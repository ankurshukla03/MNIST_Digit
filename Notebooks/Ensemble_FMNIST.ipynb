{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d679ae4ace43a060ab4bb6f9632b9c25b727866"
   },
   "source": [
    "# CNN model for Fashion MNIST Dataset\n",
    "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "## Content\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "- To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix.\n",
    "- For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "61809861a1424f0dca23b48e41abea67f55f787f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from subprocess import check_output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "num_classes = 10\n",
    "random_seed = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db50238dc2d6af1add0fa8c1495b0eaff2155198",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/fashion-mnist_train.csv',sep=',')\n",
    "test_df = pd.read_csv('/kaggle/input/fashion-mnist_test.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85ca8a588799f187ace84b5d36a2007136844010",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc13dd2ea96ba0f7859ff298cf8b076105001e6f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "224a78521bf02df4a63db81a5c6b236977064366"
   },
   "source": [
    "Now it is observed that the first column is the label data and because it has 10 classes so it is going to have from 0 to 9.The remaining columns are the actual pixel data.Here as you can see there are about 784 columns that contain pixel data. Here each row is a different image representation in the form pixel data.\n",
    "\n",
    "Now let us split the train data into x and y arrays where x represents the image data and y represents the labels.\n",
    "\n",
    "To do that we need to convert the dataframes into numpy arrays of float32 type which is the acceptable form for tensorflow and keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "54093c89ca28ecdcad8278b2b7254f77d5ffe7bf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.array(train_df, dtype = 'float32')\n",
    "test_data = np.array(test_df,dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f75548725ebbb54ff92cf7ba38449dfa265c732c"
   },
   "source": [
    "Divide the train and test data into label and data separately. \n",
    "x_train has all the column except label and header, same goes for x_test. y_train and y_test will have all the label for train and test.\n",
    "We will divide x_train and x_test so that all the values are in from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1e06308de33b833ff29072a1e7819f424cc6aeeb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train_data[:,1:]/255\n",
    "y_train = train_data[:,0]\n",
    "x_test = test_data[:,1:]/255\n",
    "y_test = test_data[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bc290a222ab9f0f2306b0aec5147d810d6041f8a"
   },
   "source": [
    "# CNN Model\n",
    "## Define the model\n",
    "## Compile the model\n",
    "## Train the model\n",
    "Shape of the image which we will feed the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e0ad749de35643e5bf48f7beca6fe380c0dd32d0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_rows = 28\n",
    "\n",
    "image_cols = 28\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "image_shape = (1,image_rows,image_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f00551b0642ed0bf2ea5967f851eb3be80b37d7"
   },
   "source": [
    "Formatting on the x_train and others according to the image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "48abc96629f10380d8f00802a3a798aaac5d7484",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],*image_shape)\n",
    "x_test = x_test.reshape(x_test.shape[0],*image_shape)\n",
    "\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50041a6f0146717f6c7cfa74bc28aa0d5c2952c6"
   },
   "source": [
    "# Define the model\n",
    "Model has been taken from [here](https://www.kaggle.com/ankurshukla03/mnist-using-ensemble-cnn-0-997). Using ensemble of CNN for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "73d8a88f7567e40808a32d586b6bad1c7508a573",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = 5\n",
    "model = [0]*nn\n",
    "\n",
    "for j in range(nn):\n",
    "    model[j] = Sequential()\n",
    "    model[j].add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(1,28,28), activation='relu',data_format='channels_first'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.4))\n",
    "    \n",
    "    model[j].add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.4))\n",
    "    \n",
    "    model[j].add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Flatten())\n",
    "    model[j].add(Dropout(0.4))\n",
    "    model[j].add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model[j].compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9ac1bed2eba86bfe5e17f64bf1828d9332fd20b0"
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "baed68427403a223ded47880dd3c7e9638d9c67e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fdcea373569b770613fd1f8d0c8ae0d0f426be96"
   },
   "source": [
    "## Train 5 CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0f3f9d92f6e0f1f9e1a957180fc24abe3557fc2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = [0] * nn\n",
    "epochs = 50\n",
    "\n",
    "# Fit the model\n",
    "for j in range(nn):\n",
    "    x_train2, x_val, y_train2, y_val = train_test_split(x_train, y_train, test_size = 0.10, random_state=random_seed)\n",
    "    history[j] = model[j].fit_generator(datagen.flow(x_train2,y_train2, batch_size=64),\n",
    "                              epochs = epochs, validation_data = (x_val,y_val),\n",
    "                              verbose = 0, steps_per_epoch=(len(x_train)//64),validation_steps=(len(x_val)//64))\n",
    "    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.2f}, Validation accuracy={3:.2f}\".format(\n",
    "        j+1,epochs,max(history[j].history['acc']),max(history[j].history['val_acc']) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f388cf923693a1afe7a9805549358f9f7af94efc"
   },
   "source": [
    "## Test Prediction Accuracy\n",
    "Now we will calculate the test loss and accuracy. We can calculate the avg loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "257d8887b637dc388605c34fa0dbda49343b2c62",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = [0]*nn\n",
    "\n",
    "for j in range(nn):\n",
    "    score[j] = model[j].evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1926744becf3c2ecc3294f9eef50737e7bb7b017",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_score = np.array(score)\n",
    "# axis = 0 means calculating across columns\n",
    "np_sum = np.sum(np_score,axis =0)\n",
    "avg_loss = (np_sum[0]/len(np_score))\n",
    "avg_accuracy = (np_sum[1]/len(np_score))\n",
    "print('Avg test loss: ', avg_loss)\n",
    "print('Avg test accuracy: ',avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "684cdc13aa38225449b834acf66e6e30212552f6",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
