{
  "cells": [
    {
      "metadata": {
        "_uuid": "9d679ae4ace43a060ab4bb6f9632b9c25b727866"
      },
      "cell_type": "markdown",
      "source": "# CNN model for Fashion MNIST Dataset\nFashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n\n## Content\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n\n- To locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix.\n- For example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below. \n"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "61809861a1424f0dca23b48e41abea67f55f787f"
      },
      "cell_type": "code",
      "source": "from subprocess import check_output\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.callbacks import TensorBoard\nfrom keras.callbacks import LearningRateScheduler\nnum_classes = 10\nrandom_seed = 10",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "## Data Exploration"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "db50238dc2d6af1add0fa8c1495b0eaff2155198"
      },
      "cell_type": "code",
      "source": "train_df = pd.read_csv('/kaggle/input/fashion-mnist_train.csv',sep=',')\ntest_df = pd.read_csv('/kaggle/input/fashion-mnist_test.csv', sep = ',')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85ca8a588799f187ace84b5d36a2007136844010"
      },
      "cell_type": "code",
      "source": "train_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dc13dd2ea96ba0f7859ff298cf8b076105001e6f"
      },
      "cell_type": "code",
      "source": "test_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "224a78521bf02df4a63db81a5c6b236977064366"
      },
      "cell_type": "markdown",
      "source": "Now it is observed that the first column is the label data and because it has 10 classes so it is going to have from 0 to 9.The remaining columns are the actual pixel data.Here as you can see there are about 784 columns that contain pixel data. Here each row is a different image representation in the form pixel data.\n\nNow let us split the train data into x and y arrays where x represents the image data and y represents the labels.\n\nTo do that we need to convert the dataframes into numpy arrays of float32 type which is the acceptable form for tensorflow and keras."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "54093c89ca28ecdcad8278b2b7254f77d5ffe7bf"
      },
      "cell_type": "code",
      "source": "train_data = np.array(train_df, dtype = 'float32')\ntest_data = np.array(test_df,dtype='float32')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f75548725ebbb54ff92cf7ba38449dfa265c732c"
      },
      "cell_type": "markdown",
      "source": "Divide the train and test data into label and data separately. \nx_train has all the column except label and header, same goes for x_test. y_train and y_test will have all the label for train and test.\nWe will divide x_train and x_test so that all the values are in from 0 to 1."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e06308de33b833ff29072a1e7819f424cc6aeeb"
      },
      "cell_type": "code",
      "source": "x_train = train_data[:,1:]/255\ny_train = train_data[:,0]\nx_test = test_data[:,1:]/255\ny_test = test_data[:,0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bc290a222ab9f0f2306b0aec5147d810d6041f8a"
      },
      "cell_type": "markdown",
      "source": "# CNN Model\n## Define the model\n## Compile the model\n## Train the model\nShape of the image which we will feed the model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e0ad749de35643e5bf48f7beca6fe380c0dd32d0"
      },
      "cell_type": "code",
      "source": "image_rows = 28\n\nimage_cols = 28\n\nbatch_size = 512\n\nimage_shape = (1,image_rows,image_cols)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3f00551b0642ed0bf2ea5967f851eb3be80b37d7"
      },
      "cell_type": "markdown",
      "source": "Formatting on the x_train and others according to the image shape"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "48abc96629f10380d8f00802a3a798aaac5d7484"
      },
      "cell_type": "code",
      "source": "x_train = x_train.reshape(x_train.shape[0],*image_shape)\nx_test = x_test.reshape(x_test.shape[0],*image_shape)\n\nx_test.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "50041a6f0146717f6c7cfa74bc28aa0d5c2952c6"
      },
      "cell_type": "markdown",
      "source": "# Define the model\nModel has been taken from [here](https://www.kaggle.com/ankurshukla03/mnist-using-ensemble-cnn-0-997). Using ensemble of CNN for the training"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73d8a88f7567e40808a32d586b6bad1c7508a573"
      },
      "cell_type": "code",
      "source": "nn = 5\nmodel = [0]*nn\n\nfor j in range(nn):\n    model[j] = Sequential()\n    model[j].add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(1,28,28), activation='relu',data_format='channels_first'))\n    model[j].add(BatchNormalization())\n    model[j].add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Dropout(0.4))\n    \n    model[j].add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Dropout(0.4))\n    \n    model[j].add(Conv2D(128, kernel_size = 4, activation='relu'))\n    model[j].add(BatchNormalization())\n    model[j].add(Flatten())\n    model[j].add(Dropout(0.4))\n    model[j].add(Dense(10, activation='softmax'))\n    \n    # Compile model\n    model[j].compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9ac1bed2eba86bfe5e17f64bf1828d9332fd20b0"
      },
      "cell_type": "markdown",
      "source": "## Data Augmentation"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "baed68427403a223ded47880dd3c7e9638d9c67e"
      },
      "cell_type": "code",
      "source": "# With data augmentation to prevent overfitting\ndatagen = ImageDataGenerator(\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fdcea373569b770613fd1f8d0c8ae0d0f426be96"
      },
      "cell_type": "markdown",
      "source": "## Train 5 CNNs"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d0f3f9d92f6e0f1f9e1a957180fc24abe3557fc2"
      },
      "cell_type": "code",
      "source": "history = [0] * nn\nepochs = 50\n\n# Fit the model\nfor j in range(nn):\n    x_train2, x_val, y_train2, y_val = train_test_split(x_train, y_train, test_size = 0.10, random_state=random_seed)\n    history[j] = model[j].fit_generator(datagen.flow(x_train2,y_train2, batch_size=64),\n                              epochs = epochs, validation_data = (x_val,y_val),\n                              verbose = 0, steps_per_epoch=(len(x_train)//64),validation_steps=(len(x_val)//64))\n    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.2f}, Validation accuracy={3:.2f}\".format(\n        j+1,epochs,max(history[j].history['acc']),max(history[j].history['val_acc']) ))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f388cf923693a1afe7a9805549358f9f7af94efc"
      },
      "cell_type": "markdown",
      "source": "## Test Prediction Accuracy\nNow we will calculate the test loss and accuracy. We can calculate the avg loss and accuracy"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "257d8887b637dc388605c34fa0dbda49343b2c62"
      },
      "cell_type": "code",
      "source": "score = [0]*nn\n\nfor j in range(nn):\n    score[j] = model[j].evaluate(x_test,y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1926744becf3c2ecc3294f9eef50737e7bb7b017"
      },
      "cell_type": "code",
      "source": "np_score = np.array(score)\n# axis = 0 means calculating across columns\nnp_sum = np.sum(np_score,axis =0)\navg_loss = (np_sum[0]/len(np_score))\navg_accuracy = (np_sum[1]/len(np_score))\nprint('Avg test loss: ', avg_loss)\nprint('Avg test accuracy: ',avg_accuracy)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "684cdc13aa38225449b834acf66e6e30212552f6"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}